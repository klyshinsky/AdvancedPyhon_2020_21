{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Из чего же сделаны классы?</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посмотрим на объект изнутри. Мы уже обратили внимание, что объект класса надо пересоздать после внесения изменения в класс. Получается, что каждый объект \"носит\" с собой все свои функции.<br>\n",
    "Среди прочего, это связано с тем, что Питон работает со ссылками на переменные, а не самими переменными. Переменная в Питоне - это не классический \"ящик\" в котором хранится значение. Это ссылка на подобный ящик.<br>\n",
    "Функция <i>dir</i> выдает список всех полей и методов объекта.\n",
    "\n",
    "Исследуем объект нашего класса морфологии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2 \n",
    "import re \n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Другое имя класса, так как он обладает несколько иной функциональностью.\n",
    "class FasterMorphology2:\n",
    "    \"\"\" Класс для быстрого морфологического анализа текстов и их векторизации.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self): # Функция инициализации объекта после его создания.\n",
    "        self.morpho = pymorphy2.MorphAnalyzer()\n",
    "        self.cash = {}\n",
    "        self.dictionary = {} # Добавим словарь для запоминания, на каком месте вектора находится какая начальная форма.\n",
    "        \n",
    "    def analyzeWords(self, words):\n",
    "        \"\"\" Проводит морфологический анализ списка токенов words.\n",
    "            Возвращает список начальных форм слов.\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w in self.cash: # Сперва ищем очередное слово в кеше.\n",
    "                res.append(self.cash[w])\n",
    "            else: # Если его там нет, проводим морфологический анализ и кешируем.\n",
    "                r = self.morpho.parse(w)[0].normal_form\n",
    "                res.append(r)\n",
    "                self.cash[w] = r\n",
    "                if r not in self.dictionary: # Также для каждой начальной формы запоминаем ее позицию в векторе.\n",
    "                    self.dictionary[r] = len(self.dictionary)+1\n",
    "        return res\n",
    "    \n",
    "    def analyzeText(self, text):\n",
    "        \"\"\" Проводит морфологический анализ строки с текстом text. \n",
    "            Выделяет из нее слова, написанные русской кириллицей.\n",
    "            Возвращает список начальных форм слов.\n",
    "        \"\"\"\n",
    "        words = [w[0] for w in re.findall(\"([А-ЯЁа-яё]+(-[А-ЯЁа-яё]+)*)\", textWP)]\n",
    "        return self.analyzeWords(words)\n",
    "        \n",
    "    # Вообще-то тоже самое умеет Counter, но ему надо сперва привести слова к начальной форме.\n",
    "    def vectorizeAsDict(self, words):\n",
    "        \"\"\" Возвращает векторное разреженное представление текста в виде словаря.\n",
    "            Текст передается как список токенов words.\n",
    "            Вместо позиции для индексации используется само слово.\n",
    "            Возвращает словарь с начальными формами в ключах и частотами этих форм.\n",
    "        \"\"\"\n",
    "        vct = {}\n",
    "        for w in words: # Для каждого слова прповодим анализ.\n",
    "            if w in self.cash:\n",
    "                vct[self.cash[w]] = vct.get(self.cash[w], 0)+1 # Считаем частоты слов.\n",
    "            else:\n",
    "                r = self.morpho.parse(w)[0].normal_form\n",
    "                res.append(r)\n",
    "                self.cash[w] = r\n",
    "                vct[r] = vct.get(r, 0)+1\n",
    "                if r not in self.dictionary:\n",
    "                    self.dictionary[r] = len(self.dictionary)\n",
    "        return vct\n",
    "    \n",
    "    def clearDict(self):\n",
    "        \"\"\" Очищает словарь. Вдруг надо пересчитать так как изменилась размерность пространства.\n",
    "        \"\"\"\n",
    "        self.dictionary={}\n",
    "    \n",
    "    def formDict(self, texts):\n",
    "        \"\"\" Сформировать словарь по тексту не формируя разметку текста.\n",
    "        \"\"\"\n",
    "        for text in texts:\n",
    "            for word in text:\n",
    "                if word not in self.cash:\n",
    "                    r = self.morpho.parse(w)[0].normal_form\n",
    "                    self.cash[word] = r\n",
    "                    if r not in self.dictionary:\n",
    "                        self.dictionary[r] = len(self.dictionary)\n",
    "    \n",
    "    def vectorizeAsList(self, words):\n",
    "        \"\"\" Возвращает векторное представление текста в виде плотного списка (включает нули).\n",
    "            Текст передается как список токенов words.\n",
    "            Позиция каждого слова в векторе определяется числом, хранимым в dictionary.\n",
    "            Возвращает словарь с начальными формами в ключах и частотами этих форм.\n",
    "        \"\"\"\n",
    "        # Сперва обновляем dictionary.\n",
    "        for word in words:\n",
    "            if word not in self.cash:\n",
    "                r = self.morpho.parse(w)[0].normal_form\n",
    "                self.cash[word] = r\n",
    "                if r not in self.dictionary:\n",
    "                    self.dictionary[r] = len(self.dictionary.keys())\n",
    "        # Теперь, когда все слова есть в кеше и словаре и известен размер вектора, можно приступать к векторизации.\n",
    "        vct = [0 for _ in self.dictionary]\n",
    "        for word in words:\n",
    "            vct[self.dictionary[self.cash[word]]] += 1\n",
    "        return vct\n",
    "    \n",
    "    def vectorizeAsList2(self, words):\n",
    "        \"\"\" Возвращает векторное представление текста в виде плотного списка (включает нули).\n",
    "            Текст передается как список токенов words. В вектор включаются только слова, находящиес в словаре.\n",
    "            Позиция каждого слова в векторе определяется числом, хранимым в dictionary.\n",
    "            Возвращает словарь с начальными формами в ключах и частотами этих форм.\n",
    "        \"\"\"\n",
    "        vct = [0 for _ in self.dictionary]\n",
    "        for word in words:\n",
    "            if word in self.cash:\n",
    "                vct[self.dictionary[self.cash[word]]] += 1\n",
    "        return vct\n",
    "\n",
    "    def vectorizeAsArray(self, words):\n",
    "        \"\"\" Возвращает векторное представление текста в виде плотного массива (включает нули).\n",
    "            Текст передается как список токенов words.\n",
    "            Позиция каждого слова в векторе определяется числом, хранимым в dictionary.\n",
    "            Возвращает словарь с начальными формами в ключах и частотами этих форм.\n",
    "        \"\"\"\n",
    "        # Сперва обновляем dictionary.\n",
    "        for word in words:\n",
    "            if word not in self.cash:\n",
    "                r = self.morpho.parse(w)[0].normal_form\n",
    "                self.cash[word] = r\n",
    "                if r not in self.dictionary:\n",
    "                    self.dictionary[r] = len(self.dictionary.keys())\n",
    "        # Теперь, когда все слова есть в кеше и словаре и известен размер вектора, можно приступать к векторизации.\n",
    "        vct = np.zeros((len(self.dictionary)))\n",
    "        for word in words:\n",
    "            vct[self.dictionary[self.cash[word]]] += 1\n",
    "        return vct\n",
    "\n",
    "    # Здесь мы заложили проблему. Функция не умеет считать расстояние между p.array.\n",
    "    def cosineSimilarity(self, a, b):\n",
    "        \"\"\" Функция расчета косинусной меры сходства между двумя векторными представлениями текста.\n",
    "            Работает по-разному в зависимости от представления вектора.\n",
    "        \"\"\"\n",
    "        if type(a) != type(b): # Тип векторов должен совпадать.\n",
    "            return None\n",
    "        if isinstance(a, list): # Если это списки, значит это плотное представление вектора.\n",
    "            # Длины векторов в этом случае должны совпадать.\n",
    "            if len(a) == 0 or len(b) == 0 or len(a) != len(b): \n",
    "                return 0\n",
    "            #sumab=sum([ai*bi for ai, bi in zip(a,b)])\n",
    "            sumab = sum([a[na]*b[na] for na in range(len(a))])\n",
    "            suma2 = sum([a[na]*a[na] for na in range(len(a))])\n",
    "            sumb2 = sum([b[na]*b[na] for na in range(len(a))])\n",
    "            return sumab / math.sqrt(suma2 * sumb2)\n",
    "        elif isinstance(a, dict): # Разреженное представление вектора - хранятся только ненулевые значения.\n",
    "            if len(a.keys()) == 0 or len(b.keys()) == 0: # Вектора должны хранить хоть что-то.\n",
    "                return 0\n",
    "            sumab=sum([a[na] * b[na] for na in set(a.keys()) & set(b.keys())])\n",
    "#            sumab=sum([a[na]*b[na] for na in a.keys() if na in b.keys()])\n",
    "            suma2=sum([a[na] * a[na] for na in a.keys()])\n",
    "            sumb2=sum([b[nb] * b[nb] for nb in b.keys()])\n",
    "            return sumab / math.sqrt(suma2 * sumb2)  \n",
    "        return 0\n",
    "    \n",
    "    def JaccardCoefficient(self, a, b):\n",
    "        \"\"\" Коэффициент Жаккара - отношение количества слов, встречающихся в обоих текстах к объединению лексики.\n",
    "        \"\"\"\n",
    "        if type(a) != type(b): # Тип векторов должен совпадать.\n",
    "            return None\n",
    "        if isinstance(a, list): # Если это списки, значит это плотное представление вектора.\n",
    "            # Длины векторов в этом случае должны совпадать.\n",
    "            if len(a) == 0 or len(b) == 0 or len(a) != len(b): \n",
    "                return 0\n",
    "            union = len(a) - [aa * bb for aa, bb in zip(a, b)].count(0)\n",
    "            intersection = len(a) - [aa + bb for aa, bb in zip(a, b)].count(0)\n",
    "            return union / intersection\n",
    "        elif isinstance(a, dict): # Разреженное представление вектора - хранятся только ненулевые значения.\n",
    "            if len(a.keys()) == 0 or len(b.keys()) == 0: # Вектора должны хранить хоть что-то.\n",
    "                return 0\n",
    "            return len(set(a.keys()) & set(b.keys())) / len(set(a.keys()) | set(b.keys()))\n",
    "        return 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JaccardCoefficient',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'analyzeText',\n",
       " 'analyzeWords',\n",
       " 'cash',\n",
       " 'clearDict',\n",
       " 'cosineSimilarity',\n",
       " 'dictionary',\n",
       " 'formDict',\n",
       " 'morpho',\n",
       " 'vectorizeAsArray',\n",
       " 'vectorizeAsDict',\n",
       " 'vectorizeAsList',\n",
       " 'vectorizeAsList2']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faster3 = FasterMorphology2()\n",
    "dir(faster3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А поле \\__dict\\__ хранит только поля объекта. Но собственно хранит, а не содержит список названий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'morpho': <pymorphy2.analyzer.MorphAnalyzer at 0x7f5e0f8ca080>,\n",
       " 'cash': {},\n",
       " 'dictionary': {}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faster3.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поле `__class__` хранит ссылку на тип объекта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.FasterMorphology2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(faster3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.FasterMorphology2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faster3.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FasterMorphology2'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faster3.__class__.__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть сам по себе тип является объектом и с ним можно точно так же работать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({'__module__': '__main__',\n",
       "              '__doc__': ' Класс для быстрого морфологического анализа текстов и их векторизации.\\n    ',\n",
       "              '__init__': <function __main__.FasterMorphology2.__init__(self)>,\n",
       "              'analyzeWords': <function __main__.FasterMorphology2.analyzeWords(self, words)>,\n",
       "              'analyzeText': <function __main__.FasterMorphology2.analyzeText(self, text)>,\n",
       "              'vectorizeAsDict': <function __main__.FasterMorphology2.vectorizeAsDict(self, words)>,\n",
       "              'clearDict': <function __main__.FasterMorphology2.clearDict(self)>,\n",
       "              'formDict': <function __main__.FasterMorphology2.formDict(self, texts)>,\n",
       "              'vectorizeAsList': <function __main__.FasterMorphology2.vectorizeAsList(self, words)>,\n",
       "              'vectorizeAsList2': <function __main__.FasterMorphology2.vectorizeAsList2(self, words)>,\n",
       "              'vectorizeAsArray': <function __main__.FasterMorphology2.vectorizeAsArray(self, words)>,\n",
       "              'cosineSimilarity': <function __main__.FasterMorphology2.cosineSimilarity(self, a, b)>,\n",
       "              'JaccardCoefficient': <function __main__.FasterMorphology2.JaccardCoefficient(self, a, b)>,\n",
       "              '__dict__': <attribute '__dict__' of 'FasterMorphology2' objects>,\n",
       "              '__weakref__': <attribute '__weakref__' of 'FasterMorphology2' objects>})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(faster3).__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавим объекту несколько новых полей и функций и посмотрим как изменится список (при помощи оператора -)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "faster5 = FasterMorphology2()\n",
    "faster4 = FasterMorphology2()\n",
    "faster4.dummy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dummy'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dir(faster4)) - set(dir(faster5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, нам вдруг захотелось, чтобы faster4 начал считать Евклидово расстояние. Для этого добавим в объект соответствующую функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EuclideDistance(self, a, b):\n",
    "    return math.sqrt(sum([aa * bb for aa, bb in zip(a, b)]))\n",
    "\n",
    "faster4.EuclidianSimilarity = EuclideDistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "EuclideDistance() missing 1 required positional argument: 'b'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8e393221bb6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfaster4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEuclidianSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: EuclideDistance() missing 1 required positional argument: 'b'"
     ]
    }
   ],
   "source": [
    "faster4.EuclidianSimilarity([1, 2, 3], [3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что-то опять пошло не так. Оказывается в Питоне функции отличаются от методов класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method FasterMorphology2.analyzeWords of <__main__.FasterMorphology2 object at 0x7f5e0f562860>>\n",
      "<function EuclideDistance at 0x7f5e0e7eeb70>\n"
     ]
    }
   ],
   "source": [
    "print(faster4.analyzeWords)\n",
    "print(faster4.EuclidianSimilarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы привязать метод к отдельному объекту необходимо вызвать специальную функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "faster4.EuclidianSimilarity = types.MethodType(EuclideDistance, faster4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EuclideDistance(a, b):\n",
    "    return math.sqrt(sum([aa * bb for aa, bb in zip(a, b)]))\n",
    "\n",
    "faster4.EuclidianSimilarity = EuclideDistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0990195135927845"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faster4.EuclidianSimilarity([1,2,3], [3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот поменять класс целиком довольно просто."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- test1 -- \n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'aha', 'uhu']\n",
      "\n",
      "-- diff -- \n",
      "set()\n",
      "\n",
      "-- test1 -- \n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'aha', 'dummy', 'uhu']\n",
      "\n",
      "-- test2 -- \n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'aha', 'dummy', 'uhu']\n"
     ]
    }
   ],
   "source": [
    "class forTests:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.aha = 0\n",
    "        self.uhu = 1\n",
    "\n",
    "test1 = forTests()\n",
    "print(\"-- test1 -- \")\n",
    "print(dir(test1))\n",
    "\n",
    "def dummyFunc(self):\n",
    "    return 0\n",
    "\n",
    "forTests.dummy = dummyFunc\n",
    "\n",
    "test2 =f orTests()\n",
    "test2.dummy()\n",
    "\n",
    "print(\"\\n-- diff -- \")\n",
    "print(set(dir(test1)) - set(dir(test2)))\n",
    "print(\"\\n-- test1 -- \")\n",
    "print(dir(test1))\n",
    "print(\"\\n-- test2 -- \")\n",
    "print(dir(test2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но обратите внимание, метод появился теперь у всех объектов данного класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'type'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(type(0)).__class__.__name__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__bool__',\n",
       " '__ceil__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__divmod__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__float__',\n",
       " '__floor__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getnewargs__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__index__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__int__',\n",
       " '__invert__',\n",
       " '__le__',\n",
       " '__lshift__',\n",
       " '__lt__',\n",
       " '__mod__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdivmod__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rlshift__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__round__',\n",
       " '__rpow__',\n",
       " '__rrshift__',\n",
       " '__rshift__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__trunc__',\n",
       " '__xor__',\n",
       " 'bit_length',\n",
       " 'conjugate',\n",
       " 'denominator',\n",
       " 'from_bytes',\n",
       " 'imag',\n",
       " 'numerator',\n",
       " 'real',\n",
       " 'to_bytes']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(type(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Перегрузка операторов</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте продолжим развивать наш учебный класс.<br>\n",
    "Еще раз внимательно посмотрим на список методов нашего класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JaccardCoefficient',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'analyzeText',\n",
       " 'analyzeWords',\n",
       " 'clearDict',\n",
       " 'cosineSimilarity',\n",
       " 'formDict',\n",
       " 'vectorizeAsArray',\n",
       " 'vectorizeAsDict',\n",
       " 'vectorizeAsList',\n",
       " 'vectorizeAsList2']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(FasterMorphology2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А что это за функции с двумя подчеркиваниями? И все ли из них такие private? <br>\n",
    "На самом деле нет. Часть из этих функций - это синонимы для операторов. Мы ведь можем складывать два множества или матрицы. Каждый раз когда мы пишем<br>\n",
    "a = b + c<br>\n",
    "на самом деле вызывается следующий код.<br>\n",
    "a = \\__add\\__(b, c)<br>\n",
    "Операторы являются удобным представлением вызовов функций. Для того, чтобы определить соответствующий оператор надо просто добавить функцию в соответствующий класс. Список всех возможных операторов записан <a href=\"https://docs.python.org/3.7/library/operator.html\">здесь</a> и <a href=\"https://docs.python.org/3/reference/datamodel.html#special-method-names\">здесь</a>.<br>\n",
    "То есть каждый класс может завести себе, например, оператор сложения, если ему это необходимо.<br>\n",
    "Давайте немного преобразим наш класс. Пусть один объект можно будет сложить с другим, после чего у него пополнится словарь. А в наш класс можно будет отправить строку при помощи оператора <<, а оператор вернет векторное представление. И еще кое-что разной степени приятности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вся перегрузка операторов находится внизу класса.\n",
    "class FasterMorphology2:\n",
    "    \"\"\" Класс для быстрого морфологического анализа текстов и их векторизации.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):  # Функция инициализации объекта после его создания.\n",
    "        self.morpho = pymorphy2.MorphAnalyzer()\n",
    "        self.cash = {}\n",
    "        # Добавим словарь для запоминания, на каком месте вектора находится какая начальная форма.\n",
    "        self.dictionary = {}\n",
    "\n",
    "    def analyzeWords(self, words):\n",
    "        \"\"\" Проводит морфологический анализ списка токенов words.\n",
    "            Возвращает список начальных форм слов.\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w in self.cash:  # Сперва ищем очередное слово в кеше.\n",
    "                res.append(self.cash[w])\n",
    "            else:  # Если его там нет, проводим морфологический анализ и кешируем.\n",
    "                r = self.morpho.parse(w)[0].normal_form\n",
    "                res.append(r)\n",
    "                self.cash[w] = r\n",
    "                # Также для каждой начальной формы запоминаем ее позицию в векторе.\n",
    "                if r not in self.dictionary:\n",
    "                    self.dictionary[r] = len(self.dictionary)\n",
    "        return res\n",
    "\n",
    "    def breakByWords(self, text):\n",
    "        \"\"\" Разбивает текст на русские слова.\n",
    "        \"\"\"\n",
    "        return [w[0].lower() for w in re.findall(\"([А-ЯЁа-яё]+(-[А-ЯЁа-яё]+)*)\", text)]\n",
    "\n",
    "    def analyzeText(self, text):\n",
    "        \"\"\" Проводит морфологический анализ строки с текстом text. \n",
    "            Выделяет из нее слова, написанные русской кириллицей.\n",
    "            Возвращает список начальных форм слов.\n",
    "        \"\"\"\n",
    "        words = self.breakByWords(text)\n",
    "        return self.analyzeWords(words)\n",
    "\n",
    "    # Вообще-то тоже самое умеет Counter, но ему надо сперва привести слова к начальной форме.\n",
    "    def vectorizeAsDict(self, words):\n",
    "        \"\"\" Возвращает векторное разреженное представление текста в виде словаря.\n",
    "            Текст передается как список токенов words.\n",
    "            Вместо позиции для индексации используется само слово.\n",
    "            Возвращает словарь с начальными формами в ключах и частотами этих форм.\n",
    "        \"\"\"\n",
    "        # Если это был текст - разбиваем на слова.\n",
    "        if isinstance(words, str):\n",
    "            words = self.breakByWords(words)\n",
    "\n",
    "        vct = {}\n",
    "        for word in words:  # Для каждого слова прповодим анализ.\n",
    "            if word in self.cash:\n",
    "                # Считаем частоты слов.\n",
    "                vct[self.cash[word]] = vct.get(self.cash[word], 0)+1\n",
    "            else:\n",
    "                r = self.morpho.parse(word)[0].normal_form\n",
    "                res.append(r)\n",
    "                self.cash[word] = r\n",
    "                vct[r] = vct.get(r, 0)+1\n",
    "                if r not in self.dictionary:\n",
    "                    self.dictionary[r] = len(self.dictionary)\n",
    "        return vct\n",
    "\n",
    "    def clearDict(self):\n",
    "        \"\"\" Очищает словарь. Вдруг надо пересчитать так как изменилась размерность пространства.\n",
    "        \"\"\"\n",
    "        self.dictionary = {}\n",
    "\n",
    "    def formDict(self, texts):\n",
    "        \"\"\" Сформировать словарь по тексту не формируя разметку текста.\n",
    "        \"\"\"\n",
    "        for text in texts:\n",
    "            for word in text:\n",
    "                if word not in self.cash:\n",
    "                    r = self.morpho.parse(word)[0].normal_form\n",
    "                    self.cash[word] = r\n",
    "                    if r not in self.dictionary:\n",
    "                        self.dictionary[r] = len(self.dictionary)\n",
    "\n",
    "    def vectorizeAsList(self, words2):\n",
    "        \"\"\" Возвращает векторное представление текста в виде плотного списка (включает нули).\n",
    "            Текст передается как список токенов words.\n",
    "            Позиция каждого слова в векторе определяется числом, хранимым в dictionary.\n",
    "            Возвращает словарь с начальными формами в ключах и частотами этих форм.\n",
    "        \"\"\"\n",
    "        # Если это был текст - разбиваем на слова.\n",
    "        if isinstance(words2, str):\n",
    "            words = self.breakByWords(words2)\n",
    "        else:\n",
    "            words = words2\n",
    "\n",
    "        # Сперва обновляем dictionary.\n",
    "        for word in words:\n",
    "            if word not in self.cash:\n",
    "                r = self.morpho.parse(word)[0].normal_form\n",
    "                self.cash[word] = r\n",
    "                if r not in self.dictionary:\n",
    "                    self.dictionary[r] = len(self.dictionary.keys())\n",
    "        # Теперь, когда все слова есть в кеше и словаре и известен размер вектора, можно приступать к векторизации.\n",
    "        vct = [0 for _ in self.dictionary]\n",
    "        for word in words:\n",
    "            vct[self.dictionary[self.cash[word]]] += 1\n",
    "        return vct\n",
    "\n",
    "    def vectorizeAsList2(self, words):\n",
    "        \"\"\" Возвращает векторное представление текста в виде плотного списка (включает нули).\n",
    "            Текст передается как список токенов words. В вектор включаются только слова, находящиес в словаре.\n",
    "            Позиция каждого слова в векторе определяется числом, хранимым в dictionary.\n",
    "            Возвращает словарь с начальными формами в ключах и частотами этих форм.\n",
    "        \"\"\"\n",
    "        vct = [0 for _ in self.dictionary]\n",
    "        for word in words:\n",
    "            if word in self.cash:\n",
    "                vct[self.dictionary[self.cash[word]]] += 1\n",
    "        return vct\n",
    "\n",
    "    def vectorizeAsArray(self, words):\n",
    "        \"\"\" Возвращает векторное представление текста в виде плотного массива (включает нули).\n",
    "            Текст передается как список токенов words.\n",
    "            Позиция каждого слова в векторе определяется числом, хранимым в dictionary.\n",
    "            Возвращает словарь с начальными формами в ключах и частотами этих форм.\n",
    "        \"\"\"\n",
    "        # Если это был текст - разбиваем на слова.\n",
    "        if isinstance(words, str):\n",
    "            words = self.breakByWords(words)\n",
    "\n",
    "        # Сперва обновляем dictionary.\n",
    "        for word in words:\n",
    "            if word not in self.cash:\n",
    "                r = self.morpho.parse(w)[0].normal_form\n",
    "                self.cash[word] = r\n",
    "                if r not in self.dictionary:\n",
    "                    self.dictionary[r] = len(self.dictionary.keys())\n",
    "        # Теперь, когда все слова есть в кеше и словаре и известен размер вектора, можно приступать к векторизации.\n",
    "        vct = np.zeros((len(self.dictionary)))\n",
    "        for word in words:\n",
    "            vct[self.dictionary[self.cash[word]]] += 1\n",
    "        return vct\n",
    "\n",
    "    # Здесь мы заложили проблему. Функция не умеет считать расстояние между p.array.\n",
    "    def cosineSimilarity(self, a, b):\n",
    "        \"\"\" Функция расчета косинусной меры сходства между двумя векторными представлениями текста.\n",
    "            Работает по-разному в зависимости от представления вектора.\n",
    "        \"\"\"\n",
    "        if type(a) != type(b):  # Тип векторов должен совпадать.\n",
    "            return None\n",
    "        # Если это списки, значит это плотное представление вектора.\n",
    "        if isinstance(a, list):\n",
    "            # Длины векторов в этом случае должны совпадать.\n",
    "            if len(a) == 0 or len(b) == 0 or len(a) != len(b):\n",
    "                return 0\n",
    "            sumab = sum([a[na]*b[na] for na in range(len(a))])\n",
    "            suma2 = sum([a[na]*a[na] for na in range(len(a))])\n",
    "            sumb2 = sum([b[na]*b[na] for na in range(len(a))])\n",
    "            return sumab/math.sqrt(suma2*sumb2)\n",
    "        # Разреженное представление вектора - хранятся только ненулевые значения.\n",
    "        elif isinstance(a, dict):\n",
    "            # Вектора должны хранить хоть что-то.\n",
    "            if len(a.keys()) == 0 or len(b.keys()) == 0:\n",
    "                return 0\n",
    "            sumab = sum([a[na] * b[na] for na in set(a.keys()) & set(b.keys())])\n",
    "#            sumab=sum([a[na]*b[na] for na in a.keys() if na in b.keys()])\n",
    "            suma2 = sum([a[na] * a[na] for na in a.keys()])\n",
    "            sumb2 = sum([b[nb] * b[nb] for nb in b.keys()])\n",
    "            return sumab / math.sqrt(suma2 * sumb2)\n",
    "        return 0\n",
    "\n",
    "    def JaccardCoefficient(self, a, b):\n",
    "        \"\"\" Коэффициент Жаккара - отношение количества слов, встречающихся в обоих текстах к объединению лексики.\n",
    "        \"\"\"\n",
    "        if type(a) != type(b):  # Тип векторов должен совпадать.\n",
    "            return None\n",
    "        # Если это списки, значит это плотное представление вектора.\n",
    "        if isinstance(a, list):\n",
    "            # Длины векторов в этом случае должны совпадать.\n",
    "            if len(a) == 0 or len(b) == 0 or len(a) != len(b):\n",
    "                return 0\n",
    "            union = len(a) - [aa*bb for aa, bb in zip(a, b)].count(0)\n",
    "            intersection = len(a)-[aa+bb for aa, bb in zip(a, b)].count(0)\n",
    "            return union / intersection\n",
    "        # Разреженное представление вектора - хранятся только ненулевые значения.\n",
    "        elif isinstance(a, dict):\n",
    "            # Вектора должны хранить хоть что-то.\n",
    "            if len(a.keys()) == 0 or len(b.keys()) == 0:\n",
    "                return 0\n",
    "            return len(set(a.keys()) & set(b.keys())) / len(set(a.keys()) | set(b.keys()))\n",
    "        return 0\n",
    "\n",
    "    def __iadd__(self, other):\n",
    "        \"\"\" Оператор добавления словаря от другого объекта.\n",
    "        \"\"\"\n",
    "        self.cash.update(other.cash)\n",
    "        for word in set(other.dictionary.keys()) - set(self.dictionary.keys()):\n",
    "            self.dictionary[word] = len(self.dictionary)\n",
    "        return self\n",
    "\n",
    "    def __lshift__(self, text):\n",
    "        \"\"\" Оператор возвращает векторное представление текста\n",
    "        \"\"\"\n",
    "        return self.vectorizeAsList(text)\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\" Текстовое представление объекта.\n",
    "        \"\"\"\n",
    "        return \"Object of class FasterMorphology2 <\" + str(id(self)) + \\\n",
    "            \">\\nCash size: \" + str(len(self.cash)) + \\\n",
    "            \"\\nDictionary size: \" + str(len(self.dictionary))\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        \"\"\" Возвращает элемент словаря при помощи квадратных скобок.\n",
    "        \"\"\"\n",
    "        if isinstance(key, slice):\n",
    "            return list(self.dictionary.keys())[key.start: key.stop: key.step]\n",
    "        else:\n",
    "            return list(self.dictionary.keys())[key]\n",
    "\n",
    "    def __bool__(self):\n",
    "        \"\"\" Класс ведет себя как булевская переменная. Проверяет было ли что-нибудь закешировано.\n",
    "        \"\"\"\n",
    "        return len(self.dictionary) != 0\n",
    "\n",
    "    def __call__(self):\n",
    "        \"\"\" Объект класса можно \"вызвать\" как функцию. Можно просто переопределить оператор \"круглые скобки\".\n",
    "        \"\"\"\n",
    "        print(\"-=* Overall results for FasterMorphology2*=-\\nCash size: \" +\n",
    "              str(len(self.cash)) + \"\\nDictionary size: \" + str(len(self.dictionary)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы добавили некоторые операторы в наш класс. Теперь опробуем их на трех произведениях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/war_and_peace.txt\", encoding=\"utf8\") as fil:\n",
    "    textWP = fil.read()\n",
    "\n",
    "with open(\"data/Kard_Orson__Igra_Jendera.fb2\") as fil:\n",
    "    textEnd = fil.read()\n",
    "    \n",
    "textMart=\"\"\n",
    "for i in range(2, 33):\n",
    "    with open(\"data/veyr/index_split_0\"+\"{:0>2}\".format(i)+\".xhtml\") as fil:\n",
    "        textMart += fil.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сперва сделаем по старой технологии, с вызовом функций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasterWP = FasterMorphology2()\n",
    "fasterMart = FasterMorphology2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.55 s, sys: 46.3 ms, total: 1.6 s\n",
      "Wall time: 1.6 s\n",
      "CPU times: user 383 ms, sys: 0 ns, total: 383 ms\n",
      "Wall time: 382 ms\n"
     ]
    }
   ],
   "source": [
    "%time vctWP = fasterWP.vectorizeAsList(textWP)\n",
    "%time vctMart = fasterMart.vectorizeAsList(textMart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 397 ms, sys: 2.5 ms, total: 399 ms\n",
      "Wall time: 397 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fasterEnd = FasterMorphology2()\n",
    "vctEnd = fasterEnd.analyzeText(textEnd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь попробуем выполнить тоже самое, но при помощи новых перегруженных операторов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object of class FasterMorphology2 <139813220091384>\n",
      "Cash size: 0\n",
      "Dictionary size: 0\n",
      "Object of class FasterMorphology2 <139813220091384>\n",
      "Cash size: 59297\n",
      "Dictionary size: 21805\n",
      "-=* Overall results for FasterMorphology2*=-\n",
      "Cash size: 65696\n",
      "Dictionary size: 23707\n",
      "CPU times: user 387 ms, sys: 15.3 ms, total: 403 ms\n",
      "Wall time: 400 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fasterEnd = FasterMorphology2()\n",
    "print(fasterEnd) # Выводим объект.\n",
    "if not fasterEnd: # Проверяем есть ли что-то в словаре.\n",
    "    fasterEnd += fasterWP # Пополняем словарь.\n",
    "    fasterEnd += fasterMart\n",
    "print(fasterEnd)\n",
    "vctEnd = fasterEnd << textEnd # Векторизуем текст.\n",
    "fasterEnd() # Вызываем метод от объекта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что не все функции являются собственно операторами. Некоторые из них - это специальные функции, вызываемые в специальных обстоятельствах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Значения параметров по умолчанию</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем разобраться с передачей параметров в функции.<br>\n",
    "Помните функцию, которая выбирала \"значимые части речи\" с ее довольно спорным списком частей речи? Было бы здорово, если бы пользователь мог передавать туда свой список частей речи, но при это неспециалист мог бы просто согласиться со списком автора функции.<br>\n",
    "Для этого существуют значения параметров по умолчанию, которые прописываются в объявлении функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обратите внимание на присвоение значения posList - именно так задается значение по умолчанию.\n",
    "def getMeaningfullWords(morph, text, posList=('ADJF', 'NOUN', 'VERB')):\n",
    "    words = []\n",
    "    tokens = re.findall('[А-Яа-яЁё]+\\-[А-Яа-яЁё]+|[А-Яа-яЁё]+', text)\n",
    "    for t in tokens:\n",
    "        pv = morph.parse(t)\n",
    "        if pv[0].tag.POS in posList:\n",
    "            words.append(pv[0].normal_form)\n",
    "    return words\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем просто вызвать функцию со своим списком частей речи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['месяц',\n",
       " 'самый',\n",
       " 'значительный',\n",
       " 'в',\n",
       " 'жизнь',\n",
       " 'обернуться',\n",
       " 'кошмар',\n",
       " 'знать',\n",
       " 'прочесть',\n",
       " 'этот',\n",
       " 'строка',\n",
       " 'думать',\n",
       " 'в',\n",
       " 'конец',\n",
       " 'конец',\n",
       " 'мой',\n",
       " 'запись',\n",
       " 'весь',\n",
       " 'найти',\n",
       " 'мочь',\n",
       " 'год',\n",
       " 'через',\n",
       " 'сто',\n",
       " 'для',\n",
       " 'отчёт',\n",
       " 'на',\n",
       " 'шесть',\n",
       " 'сутки',\n",
       " 'погибнуть',\n",
       " 'наш',\n",
       " 'команда',\n",
       " 'счесть',\n",
       " 'мёртвый',\n",
       " 'мочь',\n",
       " 'мочь',\n",
       " 'в',\n",
       " 'мой',\n",
       " 'честь',\n",
       " 'объявить',\n",
       " 'день',\n",
       " 'национальный',\n",
       " 'траур',\n",
       " 'на',\n",
       " 'мой',\n",
       " 'страница',\n",
       " 'в',\n",
       " 'википедия',\n",
       " 'появиться',\n",
       " 'запись',\n",
       " 'марк',\n",
       " 'уотня']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getMeaningfullWords(morph, textMart[1000:1500], ['ADJF', 'NOUN', 'VERB', 'PREP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А можем согласиться на список авторов функции и не передавать ничего."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['месяц',\n",
       " 'самый',\n",
       " 'значительный',\n",
       " 'жизнь',\n",
       " 'обернуться',\n",
       " 'кошмар',\n",
       " 'знать',\n",
       " 'прочесть',\n",
       " 'этот',\n",
       " 'строка',\n",
       " 'думать',\n",
       " 'конец',\n",
       " 'конец',\n",
       " 'мой',\n",
       " 'запись',\n",
       " 'весь',\n",
       " 'найти',\n",
       " 'мочь',\n",
       " 'год',\n",
       " 'сто',\n",
       " 'отчёт',\n",
       " 'шесть',\n",
       " 'сутки',\n",
       " 'погибнуть',\n",
       " 'наш',\n",
       " 'команда',\n",
       " 'счесть',\n",
       " 'мёртвый',\n",
       " 'мочь',\n",
       " 'мочь',\n",
       " 'мой',\n",
       " 'честь',\n",
       " 'объявить',\n",
       " 'день',\n",
       " 'национальный',\n",
       " 'траур',\n",
       " 'мой',\n",
       " 'страница',\n",
       " 'википедия',\n",
       " 'появиться',\n",
       " 'запись',\n",
       " 'марк',\n",
       " 'уотня']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getMeaningfullWords(morph, textMart[1000:1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Передача параметров может быть чрезвычайно удобна в нескольких случаях.\n",
    "- В подавляющем большинстве случаев функция вызывается с значениями параметров по умолчанию. \n",
    "- Вам необходимо переделать дизайн функции так, чтобы в ней появились новые параметры, но при этом необходимо чтобы весь остальной код продолжал выполняться.\n",
    "- Необходимо застраховаться от ошибки.\n",
    "- Параметр по умолчанию принимает особое значение, которое нам о чем-то говорит."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно сделать несколько параметров со значениями по умолчанию. Если при этом не передавать последовательно несколько значений с конца, то можно просто их не писать. Если мы пропустили значение из середины списка, для остальных придется писать какому параметру какое значение передается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummie1(a=0, b=1, c=2, d=3):\n",
    "    return a + b * c - d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "1\n",
      "5\n",
      "0\n",
      "(0, 1, 2, 3)\n",
      "<code object dummie1 at 0x7f28cbc0ef60, file \"<ipython-input-33-103ef1c2c247>\", line 1>\n"
     ]
    }
   ],
   "source": [
    "print(dummie1())\n",
    "print(dummie1(2))\n",
    "print(dummie1(2, 3))\n",
    "print(dummie1(2, d=4))\n",
    "print(dummie1.__defaults__)\n",
    "print(dummie1.__code__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В книге Л. Рамальо \"Python: к вершинам мастерства\" есть раздел с названием \"Значения по умолчанию изменяемого типа: плохая идея\" (с. 259). В ней приведен следующий пример. Пусть у нас есть класс автобуса, который хранит имена пассажиров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'Bill']\n",
      "['Bill', 'Charlie']\n",
      "['Carrie']\n",
      "['Carrie']\n",
      "['Carrie', 'Dave']\n",
      "True\n",
      "['Bill', 'Charlie']\n",
      "['__annotations__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__get__', '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__kwdefaults__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']\n",
      "(['Carrie', 'Dave'],)\n",
      "True\n",
      "['Carrie', 'Dave']\n"
     ]
    }
   ],
   "source": [
    "class HauntedBus:\n",
    "    \"\"\"A bus model haunted by ghost passengers\"\"\"\n",
    "\n",
    "    def __init__(self, passengers=[]):  # Вот здесь сделана ошибка, от которой потом все беды.\n",
    "        self.passengers = passengers  \n",
    "\n",
    "#     def __init__(self, passengers=None):  # Версия без ошибок.\n",
    "#         if passengers:\n",
    "#             self.passengers = passengers  \n",
    "#         else:\n",
    "#             self.passengers = []\n",
    "\n",
    "    def pick(self, name):\n",
    "        self.passengers.append(name)  \n",
    "\n",
    "    def drop(self, name):\n",
    "        self.passengers.remove(name)\n",
    "\n",
    "        \n",
    "bus1 = HauntedBus(['Alice', 'Bill'])\n",
    "print(bus1.passengers)\n",
    "#['Alice', 'Bill']\n",
    "bus1.pick('Charlie')\n",
    "bus1.drop('Alice')\n",
    "print(bus1.passengers)\n",
    "#['Bill', 'Charlie']\n",
    "bus2 = HauntedBus()\n",
    "bus2.pick('Carrie')\n",
    "print(bus2.passengers)\n",
    "#['Carrie']\n",
    "bus3 = HauntedBus()\n",
    "print(bus3.passengers)\n",
    "#['Carrie']\n",
    "bus3.pick('Dave')\n",
    "print(bus2.passengers)\n",
    "#['Carrie', 'Dave']\n",
    "print(bus2.passengers is bus3.passengers)\n",
    "#True\n",
    "print(bus1.passengers)\n",
    "#['Bill', 'Charlie']\n",
    "print(dir(HauntedBus.__init__))\n",
    "#['__annotations__', '__call__', ..., '__defaults__', ...]\n",
    "print(HauntedBus.__init__.__defaults__) # Список значений по умолчанию для конструктора класса.\n",
    "#(['Carrie', 'Dave'],)\n",
    "print(HauntedBus.__init__.__defaults__[0] is bus2.passengers) # Оказывается всем спискам присвоена ссылка на объект по умолчанию!\n",
    "#True\n",
    "bus4 = HauntedBus()\n",
    "print(bus4.passengers)\n",
    "# ['Carrie', 'Dave']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбирая этот пример мы можем увидеть, что если в конструкторе список пассажиров берется как значение по умолчанию, то списку пассажиров данного объекта присваивается ссылка на список по умолчанию (который сам по себе тоже переменная, точнее, ее значение). Соответственно, в дальнейшем все автобусы, которым мы не передали список, будут указывать на один и тот же список. <br>\n",
    "Будьте бдительны! Делайте глубокую копию со значений по умолчанию изменяемого типа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Произвольный список параметров функции</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте разеремся как передать в функцию произвольное количество параметров.<br>\n",
    "В Python можно передать переменное количество аргументов двумя способами:\n",
    "- кортеж `*args` для неименованных аргументов;\n",
    "- словарь `**kwargs` для именованных аргументов.\n",
    "\n",
    "Мы используем `*args` и `**kwargs` в качестве аргумента, когда заранее не известно, сколько значений мы хотим передать функции. Функция может принимать оба этих параметра на случай, если передача будет вестись как с именем, так и без."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult(*multipliers):\n",
    "    print(multipliers)\n",
    "    res = 1\n",
    "    for arg in multipliers:\n",
    "        res *= arg\n",
    "    return res\n",
    "\n",
    "def HTMLizer(tag, *text, **args):\n",
    "    ar = ', '.join([a[0] + '=\"'+str(a[1]) + '\"' for a in args.items()])\n",
    "    txt = ' '.join([str(t) for t in text])\n",
    "    return \"<\" + tag + \" \" + ar + \">\" + txt + \"</\" + tag + \">\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 4, 5)\n",
      "120\n",
      "<p size=\"12\", color=\"red\">that is some text</p>\n",
      "<p ></p>\n"
     ]
    }
   ],
   "source": [
    "print(mult(2, 3, 4, 5))\n",
    "print(HTMLizer(\"p\", \"that is\", \"some text\", size=12, color=\"red\"))\n",
    "print(HTMLizer(\"p\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что при передачче параметра знак звездочки означает распаковку параметров. Например, функция принимает несколько параметров. Вместо этого Вы передаете кортеж с тем же числом полей, добавив к нему знак звездочки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 4, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asd=(2, 3, 4, 5)\n",
    "mult(*asd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11111111112\n",
      "52\n",
      "('b', 'a')\n"
     ]
    }
   ],
   "source": [
    "def dummie2(a, b):\n",
    "    print(10*a+b)\n",
    "\n",
    "ddd = ('1', '2')\n",
    "dummie2(*ddd)\n",
    "\n",
    "fff = {'b': 2, 'a': 5}\n",
    "dummie2(**fff)# dummie2(a=5, b=2)\n",
    "print(tuple(fff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "s\n"
     ]
    }
   ],
   "source": [
    "ddd = {'a':1, 's':3}\n",
    "for d in ddd:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это работает не только как в примере с произвольными параметрами, но и на любых других функциях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitude:  1.23 , latitude:  2.34\n",
      "Longitude:  3.45 , latitude:  6.45\n",
      "Longitude:  6.76 , latitude:  8.98\n"
     ]
    }
   ],
   "source": [
    "def printCoords(long, lat):\n",
    "    print(\"Longitude: \", long, \", latitude: \", lat)\n",
    "    \n",
    "coords = [(1.23, 2.34), (3.45, 6.45), (6.76, 8.98)]\n",
    "for coord in coords:\n",
    "    printCoords(*coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также можно принять в функцию список аргументов по имени и в зависимости от того, что в нем есть производить те или иные действия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitude: 1.23, Latitude: 2.34\n",
      "Longitude: 3.45, Latitude: 6.45\n",
      "Longitude: 6.76, Latitude: 8.98\n",
      "Coordinates on planet Earth are Longitude: 1.23, Latitude: 2.34\n",
      "Coordinates on planet Mars are Longitude: 3.45, Latitude: 6.45\n",
      "Coordinates on planet Krypton are Longitude: 6.76, Latitude: 8.98\n"
     ]
    }
   ],
   "source": [
    "def printCoords(long, lat, **kwargs):\n",
    "    res = \"\"\n",
    "    if 'planet' in kwargs.keys():\n",
    "        res += 'Coordinates on planet ' + kwargs['planet'] + \" are \"\n",
    "    res += \"Longitude: \" + str(long) + \", Latitude: \" + str(lat)\n",
    "    print(res)\n",
    "    \n",
    "coords=[(1.23, 2.34), (3.45, 6.45), (6.76, 8.98)]\n",
    "planets=[\"Earth\", \"Mars\", \"Krypton\"]\n",
    "for coord in coords:\n",
    "    printCoords(*coord)\n",
    "for coord, planet in zip(coords, planets):\n",
    "    printCoords(*coord, planet=planet, strange='high')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Декораторы функций</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь перейдем к декораторам.<br>\n",
    "Иногда нам необходимо расширить возможности какой-то функции. Для этих целей в Питоне используются декораторы, то есть функции, которые принимают другую функцию и возвращают третью (в общем случае)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trace(func):\n",
    "    def inner(*args, **kwargs):\n",
    "        print(\"calling function:\", func.__name__, \", parameters\", args, kwargs)\n",
    "        return func(*args, **kwargs)\n",
    "    return inner\n",
    "\n",
    "@trace\n",
    "def calc(a, b):\n",
    "    return a + b\n",
    "\n",
    "calc(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling function: calc , parameters (1, 2) {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Аналогично\n",
    "def trace(func):\n",
    "    def inner(*args, **kwargs):\n",
    "        print(\"calling function:\", func.__name__, \", parameters\", args, kwargs)\n",
    "        return func(*args, **kwargs)\n",
    "    return inner\n",
    "\n",
    "def calc(a, b):\n",
    "    return a + b\n",
    "\n",
    "trace(calc)(1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что функций в общем случае три:\n",
    "- декорируемая;\n",
    "- декорирующая;\n",
    "- та, которой декорируют.\n",
    "\n",
    "Общая идея декоратора состоит в том, что мы можем некоторым образом попросить вторую функцию сделать так, чтобы вместо первой вызывалась третья. При этом третья знает о существовании первой и может использует результаты ее работы.<br>\n",
    "В некотором роде, мы не заявляем, что декорируем первой функцией. Мы скромно просим задекорировать для нас первую функцию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задекорировать функцию можно несколькими другими функциями. Порядок декораторов имеет значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "1936\n"
     ]
    }
   ],
   "source": [
    "# https://compscicenter.ru/media/slides/python_2015_autumn/2015_09_21_python_2015_autumn_93c2yAw.pdf\n",
    "\n",
    "def square(func):\n",
    "    return lambda x: func(x * x)\n",
    "\n",
    "def addsome(func):\n",
    "    return lambda x: func(x + 42)\n",
    "\n",
    "@square\n",
    "@addsome\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "print(identity(2))\n",
    "# 46\n",
    "@addsome\n",
    "@square\n",
    "def identity(x):\n",
    "    return x\n",
    "print(identity(2))\n",
    "# 1936"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важное замечание про декораторы. <br>\n",
    "Декорирующие функции выполняются по мере объявления."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addsome\n",
      "square\n",
      "-----\n",
      "square\n",
      "addsome\n"
     ]
    }
   ],
   "source": [
    "# https://compscicenter.ru/media/slides/python_2015_autumn/2015_09_21_python_2015_autumn_93c2yAw.pdf\n",
    "\n",
    "def square(func):\n",
    "    print(\"square\")\n",
    "    return lambda x: func(x * x)\n",
    "\n",
    "def addsome(func):\n",
    "    print(\"addsome\")\n",
    "    return lambda x: func(x + 42)\n",
    "\n",
    "@square\n",
    "@addsome\n",
    "def identity1(x):\n",
    "    print(\"identity 1\")\n",
    "    return x\n",
    "\n",
    "print(\"-----\")\n",
    "\n",
    "@addsome\n",
    "@square\n",
    "def identity2(x):\n",
    "    print(\"identity 2\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity 1\n",
      "46\n",
      "identity 2\n",
      "1936\n"
     ]
    }
   ],
   "source": [
    "print(identity1(2))\n",
    "# 46\n",
    "\n",
    "print(identity2(2))\n",
    "# 1936"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается, что место, где декорируется функция, например, вот такое.\n",
    "\n",
    "`\n",
    "@first\n",
    "def second():\n",
    "    pass\n",
    "`\n",
    "\n",
    "Так вот в реальности оно выглядит вот так.\n",
    "\n",
    "`\n",
    "def second():\n",
    "    pass\n",
    "second=first(second)\n",
    "`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посмотрим на библиотеку с декораторами `functools`. Например, `functools.lru_cache` кеширует результаты и при повторном вызове с теми же параметрами подставляет результаты из кеша."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trace\n",
    "def fibonacci(n): # Посчитаем числа Фибоначи.\n",
    "    if n < 2:\n",
    "        return n\n",
    "    return fibonacci(n-2) + fibonacci(n-1)\n",
    "\n",
    "@trace\n",
    "@functools.lru_cache()\n",
    "def fibonacci2(n):\n",
    "    if n<2:\n",
    "        return n\n",
    "    return fibonacci2(n-2) + fibonacci2(n-1)\n",
    "\n",
    "@functools.lru_cache()\n",
    "@trace\n",
    "def fibonacci3(n):\n",
    "    if n<2:\n",
    "        return n\n",
    "    return fibonacci3(n-2) + fibonacci3(n-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling function: fibonacci , parameters (6,) {}\n",
      "calling function: fibonacci , parameters (4,) {}\n",
      "calling function: fibonacci , parameters (2,) {}\n",
      "calling function: fibonacci , parameters (0,) {}\n",
      "calling function: fibonacci , parameters (1,) {}\n",
      "calling function: fibonacci , parameters (3,) {}\n",
      "calling function: fibonacci , parameters (1,) {}\n",
      "calling function: fibonacci , parameters (2,) {}\n",
      "calling function: fibonacci , parameters (0,) {}\n",
      "calling function: fibonacci , parameters (1,) {}\n",
      "calling function: fibonacci , parameters (5,) {}\n",
      "calling function: fibonacci , parameters (3,) {}\n",
      "calling function: fibonacci , parameters (1,) {}\n",
      "calling function: fibonacci , parameters (2,) {}\n",
      "calling function: fibonacci , parameters (0,) {}\n",
      "calling function: fibonacci , parameters (1,) {}\n",
      "calling function: fibonacci , parameters (4,) {}\n",
      "calling function: fibonacci , parameters (2,) {}\n",
      "calling function: fibonacci , parameters (0,) {}\n",
      "calling function: fibonacci , parameters (1,) {}\n",
      "calling function: fibonacci , parameters (3,) {}\n",
      "calling function: fibonacci , parameters (1,) {}\n",
      "calling function: fibonacci , parameters (2,) {}\n",
      "calling function: fibonacci , parameters (0,) {}\n",
      "calling function: fibonacci , parameters (1,) {}\n",
      "8\n",
      "-----\n",
      "calling function: fibonacci2 , parameters (6,) {}\n",
      "calling function: fibonacci2 , parameters (4,) {}\n",
      "calling function: fibonacci2 , parameters (2,) {}\n",
      "calling function: fibonacci2 , parameters (0,) {}\n",
      "calling function: fibonacci2 , parameters (1,) {}\n",
      "calling function: fibonacci2 , parameters (3,) {}\n",
      "calling function: fibonacci2 , parameters (1,) {}\n",
      "calling function: fibonacci2 , parameters (2,) {}\n",
      "calling function: fibonacci2 , parameters (5,) {}\n",
      "calling function: fibonacci2 , parameters (3,) {}\n",
      "calling function: fibonacci2 , parameters (4,) {}\n",
      "8\n",
      "-----\n",
      "calling function: fibonacci3 , parameters (6,) {}\n",
      "calling function: fibonacci3 , parameters (4,) {}\n",
      "calling function: fibonacci3 , parameters (2,) {}\n",
      "calling function: fibonacci3 , parameters (0,) {}\n",
      "calling function: fibonacci3 , parameters (1,) {}\n",
      "calling function: fibonacci3 , parameters (3,) {}\n",
      "calling function: fibonacci3 , parameters (5,) {}\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(fibonacci(6))\n",
    "print(\"-----\")\n",
    "print(fibonacci2(6))\n",
    "print(\"-----\")\n",
    "print(fibonacci3(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем аккуратно заделать недостаток нашего класса, который состоит в том, что мы не умеем считать косинусную меру для `numpy.array`. Будем использовать для этого `functools.singledispatch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Все декораторы вынесены из определения класса, так как не дело это класса считать косинусную меру. Она сама по себе.\n",
    "# А еще я заменил действие оператора << , теперь он возвращает словарь. Так все-таки проще считать косинусную меру.\n",
    "class FasterMorphology2:\n",
    "    \"\"\" Класс для быстрого морфологического анализа текстов и их векторизации.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):  # Функция инициализации объекта после его создания.\n",
    "        self.morpho = pymorphy2.MorphAnalyzer()\n",
    "        self.cash = {}\n",
    "        # Добавим словарь для запоминания, на каком месте вектора находится какая начальная форма.\n",
    "        self.dictionary = {}\n",
    "\n",
    "    def analyzeWords(self, words):\n",
    "        \"\"\" Проводит морфологический анализ списка токенов words.\n",
    "            Возвращает список начальных форм слов.\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w in self.cash:  # Сперва ищем очередное слово в кеше.\n",
    "                res.append(self.cash[w])\n",
    "            else:  # Если его там нет, проводим морфологический анализ и кешируем.\n",
    "                r = self.morpho.parse(w)[0].normal_form\n",
    "                res.append(r)\n",
    "                self.cash[w] = r\n",
    "                # Также для каждой начальной формы запоминаем ее позицию в векторе.\n",
    "                if r not in self.dictionary:\n",
    "                    self.dictionary[r] = len(self.dictionary)\n",
    "        return res\n",
    "\n",
    "    def breakByWords(self, text):\n",
    "        \"\"\" Разбивает текст на русские слова.\n",
    "        \"\"\"\n",
    "        return [w[0].lower() for w in re.findall(\"([А-ЯЁа-яё]+(-[А-ЯЁа-яё]+)*)\", text)]\n",
    "\n",
    "    def analyzeText(self, text):\n",
    "        \"\"\" Проводит морфологический анализ строки с текстом text. \n",
    "            Выделяет из нее слова, написанные русской кириллицей.\n",
    "            Возвращает список начальных форм слов.\n",
    "        \"\"\"\n",
    "        words = self.breakByWords(text)\n",
    "        return self.analyzeWords(words)\n",
    "\n",
    "    # Вообще-то тоже самое умеет Counter, но ему надо сперва привести слова к начальной форме.\n",
    "    def vectorizeAsDict(self, words):\n",
    "        \"\"\" Возвращает векторное разреженное представление текста в виде словаря.\n",
    "            Текст передается как список токенов words.\n",
    "            Вместо позиции для индексации используется само слово.\n",
    "            Возвращает словарь с начальными формами в ключах и частотами этих форм.\n",
    "        \"\"\"\n",
    "        # Если это был текст - разбиваем на слова.\n",
    "        if isinstance(words, str):\n",
    "            words = self.breakByWords(words)\n",
    "\n",
    "        vct = {}\n",
    "        for word in words:  # Для каждого слова прповодим анализ.\n",
    "            if word in self.cash:\n",
    "                # Считаем частоты слов.\n",
    "                vct[self.cash[word]] = vct.get(self.cash[word], 0) + 1\n",
    "            else:\n",
    "                r = self.morpho.parse(word)[0].normal_form\n",
    "                self.cash[word] = r\n",
    "                vct[r] = vct.get(r, 0) + 1\n",
    "                if r not in self.dictionary:\n",
    "                    self.dictionary[r] = len(self.dictionary)\n",
    "        return vct\n",
    "\n",
    "    def clearDict(self):\n",
    "        \"\"\" Очищает словарь. Вдруг надо пересчитать так как изменилась размерность пространства.\n",
    "        \"\"\"\n",
    "        self.dictionary = {}\n",
    "\n",
    "    def formDict(self, texts):\n",
    "        \"\"\" Сформировать словарь по тексту не формируя разметку текста.\n",
    "        \"\"\"\n",
    "        for text in texts:\n",
    "            for word in text:\n",
    "                if word not in self.cash:\n",
    "                    r = self.morpho.parse(word)[0].normal_form\n",
    "                    self.cash[word] = r\n",
    "                    if r not in self.dictionary:\n",
    "                        self.dictionary[r] = len(self.dictionary)\n",
    "\n",
    "    def vectorizeAsList(self, words2):\n",
    "        \"\"\" Возвращает векторное представление текста в виде плотного списка (включает нули).\n",
    "            Текст передается как список токенов words.\n",
    "            Позиция каждого слова в векторе определяется числом, хранимым в dictionary.\n",
    "            Возвращает словарь с начальными формами в ключах и частотами этих форм.\n",
    "        \"\"\"\n",
    "        # Если это был текст - разбиваем на слова.\n",
    "        if isinstance(words2, str):\n",
    "            words = self.breakByWords(words2)\n",
    "        else:\n",
    "            words = words2\n",
    "\n",
    "        # Сперва обновляем dictionary.\n",
    "        for word in words:\n",
    "            if word not in self.cash:\n",
    "                r = self.morpho.parse(word)[0].normal_form\n",
    "                self.cash[word] = r\n",
    "                if r not in self.dictionary:\n",
    "                    self.dictionary[r] = len(self.dictionary.keys())\n",
    "        # Теперь, когда все слова есть в кеше и словаре и известен размер вектора, можно приступать к векторизации.\n",
    "        vct = [0 for _ in self.dictionary]\n",
    "        for word in words:\n",
    "            vct[self.dictionary[self.cash[word]]] += 1\n",
    "        return vct\n",
    "\n",
    "    def vectorizeAsList2(self, words):\n",
    "        \"\"\" Возвращает векторное представление текста в виде плотного списка (включает нули).\n",
    "            Текст передается как список токенов words. В вектор включаются только слова, находящиес в словаре.\n",
    "            Позиция каждого слова в векторе определяется числом, хранимым в dictionary.\n",
    "            Возвращает словарь с начальными формами в ключах и частотами этих форм.\n",
    "        \"\"\"\n",
    "        vct = [0 for _ in self.dictionary]\n",
    "        for word in words:\n",
    "            if word in self.cash:\n",
    "                vct[self.dictionary[self.cash[word]]] += 1\n",
    "        return vct\n",
    "\n",
    "    def vectorizeAsArray(self, words):\n",
    "        \"\"\" Возвращает векторное представление текста в виде плотного массива (включает нули).\n",
    "            Текст передается как список токенов words.\n",
    "            Позиция каждого слова в векторе определяется числом, хранимым в dictionary.\n",
    "            Возвращает словарь с начальными формами в ключах и частотами этих форм.\n",
    "        \"\"\"\n",
    "        # Если это был текст - разбиваем на слова.\n",
    "        if isinstance(words, str):\n",
    "            words = self.breakByWords(words)\n",
    "\n",
    "        # Сперва обновляем dictionary.\n",
    "        for word in words:\n",
    "            if word not in self.cash:\n",
    "                r = self.morpho.parse(w)[0].normal_form\n",
    "                self.cash[word] = r\n",
    "                if r not in self.dictionary:\n",
    "                    self.dictionary[r] = len(self.dictionary.keys())\n",
    "        # Теперь, когда все слова есть в кеше и словаре и известен размер вектора, можно приступать к векторизации.\n",
    "        vct = np.zeros((len(self.dictionary)))\n",
    "        for word in words:\n",
    "            vct[self.dictionary[self.cash[word]]] += 1\n",
    "        return vct\n",
    "\n",
    "    def __iadd__(self, other):\n",
    "        \"\"\" Оператор добавления словаря от другого объекта.\n",
    "        \"\"\"\n",
    "        self.cash.update(other.cash)\n",
    "        for word in set(other.dictionary.keys()) - set(self.dictionary.keys()):\n",
    "            self.dictionary[word] = len(self.dictionary)\n",
    "        return self\n",
    "\n",
    "    def __lshift__(self, text):\n",
    "        \"\"\" Оператор возвращает векторное представление текста в виде словаря.\n",
    "        \"\"\"\n",
    "        return self.vectorizeAsDict(text)\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\" Текстовое представление объекта.\n",
    "        \"\"\"\n",
    "        return \"Object of class FasterMorphology2 <\" + str(id(self)) + \\\n",
    "            \">\\nCash size: \" + str(len(self.cash)) + \\\n",
    "            \"\\nDictionary size: \" + str(len(self.dictionary))\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        \"\"\" Возвращает элемент словаря при помощи квадратных скобок.\n",
    "        \"\"\"\n",
    "        if isinstance(key, slice):\n",
    "            return list(self.dictionary.keys())[key.start: key.stop: key.step]\n",
    "        else:\n",
    "            return list(self.dictionary.keys())[key]\n",
    "\n",
    "    def __bool__(self):\n",
    "        \"\"\" Класс ведет себя как булевская переменная. Проверяет было ли что-нибудь закешировано.\n",
    "        \"\"\"\n",
    "        return len(self.dictionary) != 0\n",
    "\n",
    "    def __call__(self):\n",
    "        \"\"\" Объект класса можно \"вызвать\" как функцию. Можно просто переопределить оператор \"круглые скобки\".\n",
    "        \"\"\"\n",
    "        print(\"-=* Overall results for FasterMorphology2*=-\\nCash size: \" +\n",
    "              str(len(self.cash)) + \"\\nDictionary size: \" + str(len(self.dictionary)))\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.singledispatch\n",
    "# Говорим, что у нас есть функция, которую мы будем расширять.\n",
    "def cosineSimilarity(a, b):\n",
    "    return 0\n",
    "\n",
    "\n",
    "# Навешиваем на нее декоратор, который будет вызываться только если первый параметр имеет тип list.\n",
    "@cosineSimilarity.register(list)\n",
    "def _(a, b):\n",
    "    # Длины векторов в этом случае должны совпадать.\n",
    "    if len(a) == 0 or len(b) == 0 or len(a) != len(b):\n",
    "        return 0\n",
    "    sumab = sum([na * nb for na, nb in zip(a, b)])\n",
    "    suma2 = sum([na * na for na in a])\n",
    "    sumb2 = sum([nb * nb for nb in b])\n",
    "    return sumab / math.sqrt(suma2 * sumb2)\n",
    "\n",
    "\n",
    "@cosineSimilarity.register(dict)  # Еще один декоратор для типа dict.\n",
    "def _(a, b):\n",
    "    # Вектора должны хранить хоть что-то.\n",
    "    if len(a.keys()) == 0 or len(b.keys()) == 0:\n",
    "        return 0\n",
    "    sumab = sum([a[na] * b[na] for na in set(a.keys()) & set(b.keys())])\n",
    "    suma2 = sum([a[na] * a[na] for na in a.keys()])\n",
    "    sumb2 = sum([b[nb] * b[nb] for nb in b.keys()])\n",
    "    return sumab / math.sqrt(suma2 * sumb2)\n",
    "\n",
    "\n",
    "@cosineSimilarity.register(np.ndarray)  # И декоратор для типа np.array.\n",
    "def _(a, b):\n",
    "    # Длины векторов в этом случае должны совпадать.\n",
    "    if len(a) == 0 or len(b) == 0 or len(a) != len(b):\n",
    "        return 0\n",
    "    sumab = sum([na * nb for na, nb in zip(a, b)])\n",
    "    suma2 = sum([na * na for na in a])\n",
    "    sumb2 = sum([nb * nb for nb in b])\n",
    "    return sumab / math.sqrt(suma2 * sumb2)\n",
    "\n",
    "\n",
    "@functools.singledispatch\n",
    "def JaccardCoefficient(a, b):  # Повторяем для коэффициента Жаккара.\n",
    "    return 0\n",
    "\n",
    "\n",
    "@JaccardCoefficient.register(list)\n",
    "def _(a, b):\n",
    "    # Длины векторов в этом случае должны совпадать.\n",
    "    if len(a) == 0 or len(b) == 0 or len(a) != len(b):\n",
    "        return 0\n",
    "    union = len(a) - [aa * bb for aa, bb in zip(a, b)].count(0)\n",
    "    intersection = len(a) - [aa + bb for aa, bb in zip(a, b)].count(0)\n",
    "    return union/intersection\n",
    "\n",
    "\n",
    "@JaccardCoefficient.register(dict)\n",
    "def _(a, b):\n",
    "    # Вектора должны хранить хоть что-то.\n",
    "    if len(a.keys()) == 0 or len(b.keys()) == 0:\n",
    "        return 0\n",
    "    return len(set(a.keys()) & set(b.keys())) / len(set(a.keys()) | set(b.keys()))\n",
    "\n",
    "\n",
    "@JaccardCoefficient.register(np.ndarray)\n",
    "def _(a, b):\n",
    "    # Длины векторов в этом случае должны совпадать.\n",
    "    if len(a) == 0 or len(b) == 0 or len(a) != len(b):\n",
    "        return 0\n",
    "    union = len(a) - [aa * bb for aa, bb in zip(a, b)].count(0)\n",
    "    intersection = len(a) - [aa + bb for aa, bb in zip(a, b)].count(0)\n",
    "    return union / intersection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142857142857143\n",
      "0.7142857142857143\n",
      "0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим как ведет себя косинус для разных типов.\n",
    "a = [1, 2 ,3]\n",
    "b = [3, 2, 1]\n",
    "\n",
    "print(cosineSimilarity(a, b))\n",
    "\n",
    "a = {1: 1, 2: 2, 3: 3}\n",
    "b = {1: 3, 2: 2, 3: 1}\n",
    "\n",
    "print(cosineSimilarity(a, b))\n",
    "   \n",
    "a = np.array(([1, 2, 3]))\n",
    "b = np.array(([3, 2, 1]))\n",
    "\n",
    "print(cosineSimilarity(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь посмотрим как будут вести себя векторы от нашей кешированной морфологии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasterWP = FasterMorphology2()\n",
    "fasterMart = FasterMorphology2()\n",
    "fasterEnd = FasterMorphology2()\n",
    "vctWP = fasterWP << textWP\n",
    "fasterMart += fasterWP\n",
    "vctMart = fasterMart << textMart\n",
    "fasterEnd += fasterWP\n",
    "fasterEnd += fasterMart\n",
    "vctEnd = fasterEnd << textEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity of War and Peace and Ender's Game 0.8877558800566507\n",
      "Cosine similarity of Martian and Ender's Game 0.8558887385483673\n",
      "Cosine similarity of War and Peace and Martian 0.8042099465818117\n",
      "Jaccard similarity of War and Peace and Ender's Game 0.24524534043362495\n",
      "Jaccard similarity of Martian and Ender's Game 0.3274018379281537\n",
      "Jaccard similarity of War and Peace and Martian 0.2114193992203623\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine similarity of War and Peace and Ender's Game\", cosineSimilarity(vctWP, vctEnd))\n",
    "print(\"Cosine similarity of Martian and Ender's Game\", cosineSimilarity(vctMart, vctEnd))\n",
    "print(\"Cosine similarity of War and Peace and Martian\", cosineSimilarity(vctMart, vctWP))\n",
    "\n",
    "print(\"Jaccard similarity of War and Peace and Ender's Game\", JaccardCoefficient(vctWP, vctEnd))\n",
    "print(\"Jaccard similarity of Martian and Ender's Game\", JaccardCoefficient(vctMart, vctEnd))\n",
    "print(\"Jaccard similarity of War and Peace and Martian\", JaccardCoefficient(vctMart, vctWP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да, при таком маленьком пересечении лексики слишком большое совпадение косинусных мер. Давайте посчитаем только для значимых частей речи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Все декораторы вынесены из определения класса, так как не дело это класса считать косинусную меру. Она сама по себе.\n",
    "# А еще я заменил действие оператора << , теперь он возвращает словарь. Так все-таки проще считать косинусную меру.\n",
    "# Заведен список значимых частей речи, в соответствии с которым проводится фильтрация результатов.\n",
    "# Теперь у нас есть два закешированных списка: интересующей нас части речи и остальные.\n",
    "# Как следствие, пришлось переписать все части, которые касаются кеширования результатов.\n",
    "class FasterMorphology2:\n",
    "    \"\"\" Класс для быстрого морфологического анализа текстов и их векторизации.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):  # Функция инициализации объекта после его создания.\n",
    "        self.morpho = pymorphy2.MorphAnalyzer()\n",
    "        # Теперь надо различать слова, которые нам нравятся, не нравятся и которые не встретились.\n",
    "        self.cashPos = {}\n",
    "        self.cashNeg = []\n",
    "        # Добавим словарь для запоминания, на каком месте вектора находится какая начальная форма.\n",
    "        self.dictionary = {}\n",
    "        self.imPoS = ['ADJF', 'NOUN', 'VERB', 'INFN', 'PRTF', 'GRND']\n",
    "\n",
    "    def analyzeWords(self, words):\n",
    "        \"\"\" Проводит морфологический анализ списка токенов words.\n",
    "            Возвращает список начальных форм слов.\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        for word in words:\n",
    "            if word in self.cashPos:  # Сперва ищем очередное слово в кеше.\n",
    "                res.append(self.cashPos[word])\n",
    "            if word in self.cashNeg:  # Сперва ищем очередное слово в кеше.\n",
    "                pass\n",
    "            else:  # Если его там нет, проводим морфологический анализ и кешируем.\n",
    "                r = self.morpho.parse(word)\n",
    "                if r[0].tag.POS in self.imPoS:\n",
    "                    r = r[0].normal_form\n",
    "                    res.append(r)\n",
    "                    self.cashPos[word] = r\n",
    "                    # Также для каждой начальной формы запоминаем ее позицию в векторе.\n",
    "                    if r not in self.dictionary:\n",
    "                        self.dictionary[r] = len(self.dictionary)\n",
    "                else:\n",
    "                    self.cashNeg.append(word)\n",
    "        return res\n",
    "\n",
    "    def breakByWords(self, text):\n",
    "        \"\"\" Разбивает текст на русские слова.\n",
    "        \"\"\"\n",
    "        return [w[0].lower() for w in re.findall(\"([А-ЯЁа-яё]+(-[А-ЯЁа-яё]+)*)\", text)]\n",
    "\n",
    "    def analyzeText(self, text):\n",
    "        \"\"\" Проводит морфологический анализ строки с текстом text. \n",
    "            Выделяет из нее слова, написанные русской кириллицей.\n",
    "            Возвращает список начальных форм слов.\n",
    "        \"\"\"\n",
    "        words = self.breakByWords(text)\n",
    "        return self.analyzeWords(words)\n",
    "\n",
    "    # Вообще-то тоже самое умеет Counter, но ему надо сперва привести слова к начальной форме.\n",
    "    def vectorizeAsDict(self, words):\n",
    "        \"\"\" Возвращает векторное разреженное представление текста в виде словаря.\n",
    "            Текст передается как список токенов words.\n",
    "            Вместо позиции для индексации используется само слово.\n",
    "            Возвращает словарь с начальными формами в ключах и частотами этих форм.\n",
    "        \"\"\"\n",
    "        # Если это был текст - разбиваем на слова.\n",
    "        if isinstance(words, str):\n",
    "            words = self.breakByWords(words)\n",
    "\n",
    "        vct = {}\n",
    "        for word in words:  # Для каждого слова прповодим анализ.\n",
    "            if word in self.cashPos:  # Это закешированное слово со значимой частью речи.\n",
    "                # Считаем частоты слов.\n",
    "                vct[self.cashPos[word]] = vct.get(self.cashPos[word], 0)+1\n",
    "            elif word in self.cashNeg:  # Это закешированное слово не со значимой частью речи.\n",
    "                pass\n",
    "            else:\n",
    "                r = self.morpho.parse(word)\n",
    "                if r[0].tag.POS in self.imPoS:\n",
    "                    r = r[0].normal_form\n",
    "                    self.cashPos[word] = r\n",
    "                    vct[r] = 1\n",
    "                    if r not in self.dictionary:\n",
    "                        self.dictionary[r] = len(self.dictionary)\n",
    "                else:\n",
    "                    # Мы ничего не хотим знать про это слово.\n",
    "                    self.cashNeg.append(word)\n",
    "\n",
    "        return vct\n",
    "\n",
    "    def clearDict(self):\n",
    "        \"\"\" Очищает словарь. Вдруг надо пересчитать так как изменилась размерность пространства.\n",
    "        \"\"\"\n",
    "        self.dictionary = {}\n",
    "\n",
    "    def formDict(self, texts):\n",
    "        \"\"\" Сформировать словарь по тексту не формируя разметку текста.\n",
    "        \"\"\"\n",
    "        for text in texts:\n",
    "            for word in text:\n",
    "                if word not in self.cashPos and word not in self.cashNeg:\n",
    "                    r = self.morpho.parse(word)\n",
    "                    if r[0].tag.POS in self.imPoS:\n",
    "                        r = r[0].normal_form\n",
    "                        self.cashPos[word] = r\n",
    "                        if r not in self.dictionary:\n",
    "                            self.dictionary[r] = len(self.dictionary)\n",
    "                    else:\n",
    "                        # Мы ничего не хотим знать про это слово.\n",
    "                        self.cashNeg.append(word)\n",
    "\n",
    "    def vectorizeAsList(self, words2):\n",
    "        \"\"\" Возвращает векторное представление текста в виде плотного списка (включает нули).\n",
    "            Текст передается как список токенов words.\n",
    "            Позиция каждого слова в векторе определяется числом, хранимым в dictionary.\n",
    "            Возвращает словарь с начальными формами в ключах и частотами этих форм.\n",
    "        \"\"\"\n",
    "        # Если это был текст - разбиваем на слова.\n",
    "        if isinstance(words2, str):\n",
    "            words = self.breakByWords(words2)\n",
    "        else:\n",
    "            words = words2\n",
    "\n",
    "        # Сперва обновляем dictionary.\n",
    "        for word in words:\n",
    "            if word in self.cashNeg:\n",
    "                pass\n",
    "            elif word not in self.cashPos:\n",
    "                r = self.morpho.parse(word)\n",
    "                if r[0].tag.POS in self.imPoS:\n",
    "                    r = r[0].normal_form\n",
    "                    self.cashPos[word] = r\n",
    "                    if r not in self.dictionary:\n",
    "                        self.dictionary[r] = len(self.dictionary.keys())\n",
    "                else:\n",
    "                    # Мы ничего не хотим знать про это слово.\n",
    "                    self.cashNeg.append(word)\n",
    "        # Теперь, когда все слова есть в кеше и словаре и известен размер вектора, можно приступать к векторизации.\n",
    "        vct = [0 for _ in self.dictionary]\n",
    "        for word in words:\n",
    "            if word in self.cashPos:\n",
    "                vct[self.dictionary[self.cashPos[word]]] += 1\n",
    "        return vct\n",
    "\n",
    "    def vectorizeAsList2(self, words):\n",
    "        \"\"\" Возвращает векторное представление текста в виде плотного списка (включает нули).\n",
    "            Текст передается как список токенов words. В вектор включаются только слова, находящиес в словаре.\n",
    "            Позиция каждого слова в векторе определяется числом, хранимым в dictionary.\n",
    "            Возвращает словарь с начальными формами в ключах и частотами этих форм.\n",
    "        \"\"\"\n",
    "        vct = [0 for _ in self.dictionary]\n",
    "        for word in words:\n",
    "            if word in self.cashPos:\n",
    "                vct[self.dictionary[self.cashPos[word]]] += 1\n",
    "        return vct\n",
    "\n",
    "    def vectorizeAsArray(self, words):\n",
    "        \"\"\" Возвращает векторное представление текста в виде плотного массива (включает нули).\n",
    "            Текст передается как список токенов words.\n",
    "            Позиция каждого слова в векторе определяется числом, хранимым в dictionary.\n",
    "            Возвращает словарь с начальными формами в ключах и частотами этих форм.\n",
    "        \"\"\"\n",
    "        # Если это был текст - разбиваем на слова.\n",
    "        if isinstance(words, str):\n",
    "            words = self.breakByWords(words)\n",
    "\n",
    "        # Сперва обновляем dictionary.\n",
    "        for word in words:\n",
    "            if word in self.cashNeg:\n",
    "                pass\n",
    "            elif word not in self.cashPos:\n",
    "                r = self.morpho.parse(word)\n",
    "                if r[0].tag.POS in self.imPoS:\n",
    "                    r = r[0].normal_form\n",
    "                    self.cashPos[word] = r\n",
    "                    if r not in self.dictionary:\n",
    "                        self.dictionary[r] = len(self.dictionary.keys())\n",
    "                else:\n",
    "                    # Мы ничего не хотим знать про это слово.\n",
    "                    self.cashNeg.append(word)\n",
    "        # Теперь, когда все слова есть в кеше и словаре и известен размер вектора, можно приступать к векторизации.\n",
    "        vct = np.zeros((len(self.dictionary)))\n",
    "        for word in words:\n",
    "            if word in self.cashPos:\n",
    "                vct[self.dictionary[self.cashPos[word]]] += 1\n",
    "        return vct\n",
    "\n",
    "    def __iadd__(self, other):\n",
    "        \"\"\" Оператор добавления словаря от другого объекта.\n",
    "        \"\"\"\n",
    "        self.cashPos.update(other.cashPos)\n",
    "        self.cashNeg = list(set(self.cashNeg) | set(other.cashNeg))\n",
    "        for word in set(other.dictionary.keys())-set(self.dictionary.keys()):\n",
    "            self.dictionary[word] = len(self.dictionary)\n",
    "        return self\n",
    "\n",
    "    def __lshift__(self, text):\n",
    "        \"\"\" Оператор возвращает векторное представление текста в виде словаря.\n",
    "        \"\"\"\n",
    "        return self.vectorizeAsDict(text)\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\" Текстовое представление объекта.\n",
    "        \"\"\"\n",
    "        return \"Object of class FasterMorphology2 <\"+str(id(self)) + \\\n",
    "            \">\\nPositive cash size: \"+str(len(self.cashPos)) + \\\n",
    "            \">\\nNegative cash size: \"+str(len(self.cashNeg)) + \\\n",
    "            \"\\nDictionary size: \"+str(len(self.dictionary))\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        \"\"\" Возвращает элемент словаря при помощи квадратных скобок.\n",
    "        \"\"\"\n",
    "        if isinstance(key, slice):\n",
    "            return list(self.dictionary.keys())[key.start: key.stop: key.step]\n",
    "        else:\n",
    "            return list(self.dictionary.keys())[key]\n",
    "\n",
    "    def __bool__(self):\n",
    "        \"\"\" Класс ведет себя как булевская переменная. Проверяет было ли что-нибудь закешировано.\n",
    "        \"\"\"\n",
    "        return len(self.dictionary) != 0\n",
    "\n",
    "    def __call__(self):\n",
    "        \"\"\" Объект класса можно \"вызвать\" как функцию. Можно просто переопределить оператор \"круглые скобки\".\n",
    "        \"\"\"\n",
    "        print(\"-=* Overall results for FasterMorphology2*=-\\nPositive cash size: \"+str(len(self.cashPos)) +\n",
    "              \"Negative cash size: \"+str(len(self.cashNeg)) +\n",
    "              \"\\nDictionary size: \"+str(len(self.dictionary)))\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasterWP=FasterMorphology2()\n",
    "fasterMart=FasterMorphology2()\n",
    "fasterEnd=FasterMorphology2()\n",
    "vctWP=fasterWP<<textWP\n",
    "fasterMart+=fasterWP\n",
    "vctMart=fasterMart<<textMart\n",
    "fasterEnd+=fasterWP\n",
    "fasterEnd+=fasterMart\n",
    "vctEnd=fasterEnd<<textEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity of War and Peace and Ender's Game 0.6191383100993432\n",
      "Cosine similarity of Martian and Ender's Game 0.6791956209782578\n",
      "Cosine similarity of War and Peace and Martian 0.6441131111259766\n",
      "Jaccard similarity of War and Peace and Ender's Game 0.23424136838770984\n",
      "Jaccard similarity of Martian and Ender's Game 0.30856387498819754\n",
      "Jaccard similarity of War and Peace and Martian 0.19728585276261415\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Old version\n",
    "Cosine similarity of War and Peace and Ender's Game 0.8877558800566507\n",
    "Cosine similarity of Martian and Ender's Game 0.8558887385483673\n",
    "Cosine similarity of War and Peace and Martian 0.8042099465818117\n",
    "Jaccard similarity of War and Peace and Ender's Game 0.24524534043362495\n",
    "Jaccard similarity of Martian and Ender's Game 0.3274018379281537\n",
    "Jaccard similarity of War and Peace and Martian 0.2114193992203623\n",
    "\"\"\"\n",
    "\n",
    "print(\"Cosine similarity of War and Peace and Ender's Game\", cosineSimilarity(vctWP, vctEnd))\n",
    "print(\"Cosine similarity of Martian and Ender's Game\", cosineSimilarity(vctMart, vctEnd))\n",
    "print(\"Cosine similarity of War and Peace and Martian\", cosineSimilarity(vctMart, vctWP))\n",
    "\n",
    "print(\"Jaccard similarity of War and Peace and Ender's Game\", JaccardCoefficient(vctWP, vctEnd))\n",
    "print(\"Jaccard similarity of Martian and Ender's Game\", JaccardCoefficient(vctMart, vctEnd))\n",
    "print(\"Jaccard similarity of War and Peace and Martian\", JaccardCoefficient(vctMart, vctWP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При небольшом уменьшении меры Жаккара косинусная мера значительно уменьшилась. Помимо этого, поменялась и схожесть текстов: теперь \"Марсианин\" больше похож на \"Игру Эндера\", чем на \"Войну и мир\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представим себе теперь, что мы хотим получить доступ к длине словаря, но при этом хотим организовать доступ так, чтобы пользователь не обращался к самому словарю. Для этого у нас есть два пути: написать функцию, которая будет возвращать длину словаря, или использовать `@property`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PartOfMorpho1:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.morpho = pymorphy2.MorphAnalyzer()\n",
    "        # Теперь надо различать слова, которые нам нравятся, не нравятся и которые не встретились.\n",
    "        self.cashPos = {}\n",
    "        self.cashNeg = []\n",
    "        # Добавим словарь для запоминания, на каком месте вектора находится какая начальная форма.\n",
    "        self.dictionary = {}\n",
    "        self.imPoS = ['ADJF', 'NOUN', 'VERB', 'INFN', 'PRTF', 'GRND']\n",
    "\n",
    "    def clear_dict(self):\n",
    "        \"\"\" Очищает словарь. Вдруг надо пересчитать так как изменилась размерность пространства.\n",
    "        \"\"\"\n",
    "        self.dictionary = {}\n",
    "\n",
    "    def breakByWords(self, text):\n",
    "        \"\"\" Разбивает текст на русские слова.\n",
    "        \"\"\"\n",
    "        return [w[0].lower() for w in re.findall(\"([А-ЯЁа-яё]+(-[А-ЯЁа-яё]+)*)\", text)]\n",
    "\n",
    "    def vectorizeAsDict(self, words):\n",
    "        \"\"\" Возвращает векторное разреженное представление текста в виде словаря.\n",
    "            Текст передается как список токенов words.\n",
    "            Вместо позиции для индексации используется само слово.\n",
    "            Возвращает словарь с начальными формами в ключах и частотами этих форм.\n",
    "        \"\"\"\n",
    "        # Если это был текст - разбиваем на слова.\n",
    "        if isinstance(words, str):\n",
    "            words = self.breakByWords(words)\n",
    "\n",
    "        vct = {}\n",
    "        for word in words:  # Для каждого слова прповодим анализ.\n",
    "            if word in self.cashPos:  # Это закешированное слово со значимой частью речи.\n",
    "                # Считаем частоты слов.\n",
    "                vct[self.cashPos[word]] = vct.get(self.cashPos[word], 0)+1\n",
    "            elif word in self.cashNeg:  # Это закешированное слово не со значимой частью речи.\n",
    "                pass\n",
    "            else:\n",
    "                r = self.morpho.parse(word)\n",
    "                if r[0].tag.POS in self.imPoS:\n",
    "                    r = r[0].normal_form\n",
    "                    self.cashPos[word] = r\n",
    "                    vct[r] = 1\n",
    "                    if r not in self.dictionary:\n",
    "                        self.dictionary[r] = len(self.dictionary)\n",
    "                else:\n",
    "                    # Мы ничего не хотим знать про это слово.\n",
    "                    self.cashNeg.append(word)\n",
    "\n",
    "        return vct\n",
    "\n",
    "    def get_dict_len(self):\n",
    "        \"\"\" Решение при помощи специальной функции.\n",
    "        \"\"\"\n",
    "        return len(self.dictionary.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6885"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo1 = PartOfMorpho1()\n",
    "mo1.vectorizeAsDict(textEnd)\n",
    "mo1.get_dict_len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PartOfMorpho2:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.morpho = pymorphy2.MorphAnalyzer()\n",
    "        # Теперь надо различать слова, которые нам нравятся, не нравятся и которые не встретились.\n",
    "        self.cashPos = {}\n",
    "        self.cashNeg = []\n",
    "        # Добавим словарь для запоминания, на каком месте вектора находится какая начальная форма.\n",
    "        self.dictionary = {}\n",
    "        self.imPoS = ['ADJF', 'NOUN', 'VERB', 'INFN', 'PRTF', 'GRND']\n",
    "\n",
    "    def clear_dict(self):\n",
    "        \"\"\" Очищает словарь. Вдруг надо пересчитать так как изменилась размерность пространства.\n",
    "        \"\"\"\n",
    "        self.dictionary = {}\n",
    "\n",
    "    def breakByWords(self, text):\n",
    "        \"\"\" Разбивает текст на русские слова.\n",
    "        \"\"\"\n",
    "        return [w[0].lower() for w in re.findall(\"([А-ЯЁа-яё]+(-[А-ЯЁа-яё]+)*)\", text)]\n",
    "\n",
    "    def vectorizeAsDict(self, words):\n",
    "        \"\"\" Возвращает векторное разреженное представление текста в виде словаря.\n",
    "            Текст передается как список токенов words.\n",
    "            Вместо позиции для индексации используется само слово.\n",
    "            Возвращает словарь с начальными формами в ключах и частотами этих форм.\n",
    "        \"\"\"\n",
    "        # Если это был текст - разбиваем на слова.\n",
    "        if isinstance(words, str):\n",
    "            words = self.breakByWords(words)\n",
    "\n",
    "        vct = {}\n",
    "        for word in words:  # Для каждого слова прповодим анализ.\n",
    "            if word in self.cashPos:  # Это закешированное слово со значимой частью речи.\n",
    "                # Считаем частоты слов.\n",
    "                vct[self.cashPos[word]] = vct.get(self.cashPos[word], 0)+1\n",
    "            elif word in self.cashNeg:  # Это закешированное слово не со значимой частью речи.\n",
    "                pass\n",
    "            else:\n",
    "                r = self.morpho.parse(word)\n",
    "                if r[0].tag.POS in self.imPoS:\n",
    "                    r = r[0].normal_form\n",
    "                    self.cashPos[word] = r\n",
    "                    vct[r] = 1\n",
    "                    if r not in self.dictionary:\n",
    "                        self.dictionary[r] = len(self.dictionary)\n",
    "                else:\n",
    "                    # Мы ничего не хотим знать про это слово.\n",
    "                    self.cashNeg.append(word)\n",
    "\n",
    "        return vct\n",
    "\n",
    "    @property\n",
    "    def get_dict_len(self):\n",
    "        \"\"\" Решение при помощи декоратора @property.\n",
    "        \"\"\"\n",
    "        return len(self.dictionary.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6885"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo2 = PartOfMorpho2()\n",
    "mo2.vectorizeAsDict(textEnd)\n",
    "mo2.get_dict_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что писать в такое свойство нельзя. Это позволяет ограничить доступ на чтение и на запись."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "can't set attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-07df7217d2f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmo2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dict_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: can't set attribute"
     ]
    }
   ],
   "source": [
    "mo2.get_dict_len = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но представим себе, что такое в принципе возможно. Например, мы можем оставить в словаре только N самых частотных слов, если размер словаря больше N. В таком случае опять возможны два решения - с помощью специальной функции и декоратора. Рассмотрим только второй вариант - от него просто перейти к первому."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PartOfMorpho3:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.morpho = pymorphy2.MorphAnalyzer()\n",
    "        # Теперь надо различать слова, которые нам нравятся, не нравятся и которые не встретились.\n",
    "        self.cashPos = {}\n",
    "        self.cashNeg = []\n",
    "        # Добавим словарь для запоминания, на каком месте вектора находится какая начальная форма.\n",
    "        self.dictionary = {}\n",
    "        self.imPoS = ['ADJF', 'NOUN', 'VERB', 'INFN', 'PRTF', 'GRND']\n",
    "\n",
    "    def clear_dict(self):\n",
    "        \"\"\" Очищает словарь. Вдруг надо пересчитать так как изменилась размерность пространства.\n",
    "        \"\"\"\n",
    "        self.dictionary = {}\n",
    "\n",
    "    def breakByWords(self, text):\n",
    "        \"\"\" Разбивает текст на русские слова.\n",
    "        \"\"\"\n",
    "        return [w[0].lower() for w in re.findall(\"([А-ЯЁа-яё]+(-[А-ЯЁа-яё]+)*)\", text)]\n",
    "\n",
    "    def vectorizeAsDict(self, words):\n",
    "        \"\"\" Возвращает векторное разреженное представление текста в виде словаря.\n",
    "            Текст передается как список токенов words.\n",
    "            Вместо позиции для индексации используется само слово.\n",
    "            Возвращает словарь с начальными формами в ключах и частотами этих форм.\n",
    "        \"\"\"\n",
    "        # Если это был текст - разбиваем на слова.\n",
    "        if isinstance(words, str):\n",
    "            words = self.breakByWords(words)\n",
    "\n",
    "        vct = {}\n",
    "        for word in words:  # Для каждого слова прповодим анализ.\n",
    "            if word in self.cashPos:  # Это закешированное слово со значимой частью речи.\n",
    "                # Считаем частоты слов.\n",
    "                vct[self.cashPos[word]] = vct.get(self.cashPos[word], 0)+1\n",
    "            elif word in self.cashNeg:  # Это закешированное слово не со значимой частью речи.\n",
    "                pass\n",
    "            else:\n",
    "                r = self.morpho.parse(word)\n",
    "                if r[0].tag.POS in self.imPoS:\n",
    "                    r = r[0].normal_form\n",
    "                    self.cashPos[word] = r\n",
    "                    vct[r] = 1\n",
    "                    if r not in self.dictionary:\n",
    "                        self.dictionary[r] = len(self.dictionary)\n",
    "                else:\n",
    "                    # Мы ничего не хотим знать про это слово.\n",
    "                    self.cashNeg.append(word)\n",
    "\n",
    "        return vct\n",
    "\n",
    "    @property\n",
    "    def dict_len(self):\n",
    "        \"\"\" Решение при помощи декоратора @property.\n",
    "        \"\"\"\n",
    "        return len(self.dictionary.keys())\n",
    "\n",
    "    @dict_len.setter\n",
    "    def dict_len(self, length):\n",
    "        \"\"\" Решение при помощи декоратора @property.\n",
    "        \"\"\"\n",
    "        if length < len(self.dictionary.keys()):\n",
    "            self.dictionary = {x[0]: x[1] for x in\n",
    "                               sorted(self.dictionary.items(), key=lambda x: x[1])[:length]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_items([('орсон', 0), ('карда', 1), ('скотт', 2), ('игра', 3), ('эндёр', 4), ('один', 5), ('самый', 6), ('яркий', 7), ('имя', 8), ('современный', 9), ('научный', 10), ('фантастика', 11), ('произведение', 12), ('писатель', 13), ('высокий', 14), ('премия', 15), ('хьюго', 16), ('небьюла', 17), ('локус', 18), ('главный', 19), ('мера', 20), ('талант', 21), ('выделять', 22), ('творение', 23), ('хороший', 24), ('космический', 25), ('роман', 26), ('выступать', 27), ('неподдельный', 28), ('оригинальность', 29), ('сюжет', 30), ('откровенный', 31), ('мощный', 32), ('эмоциональность', 33), ('история', 34), ('эндрю', 35), ('уиггин', 36), ('великий', 37), ('полководец', 38), ('эра', 39), ('межзвёздный', 40), ('флот', 41), ('земля', 42), ('вести', 43), ('отчаянный', 44), ('борьба', 45), ('жестокий', 46), ('негуманоидный', 47), ('пришелец', 48), ('отобрать', 49), ('ребёнок', 50), ('военный', 51), ('готовить', 52), ('особа', 53), ('программа', 54), ('командный', 55), ('состав', 56), ('земной', 57), ('армад', 58), ('этот', 59), ('мальчишка', 60), ('выполнять', 61), ('свой', 62), ('предназначение', 63), ('одержать', 64), ('ослепительный', 65), ('оглушительный', 66), ('победа', 67), ('какой', 68), ('быть', 69), ('военачальник', 70), ('прошлое', 71), ('битва', 72), ('ассоциация', 73), ('автор', 74), ('фэнтези', 75), ('америка', 76), ('год', 77), ('категория', 78), ('достижение', 79), ('е', 80), ('михайлич', 81), ('виггинс', 82), ('бесплатный', 83), ('библиотека', 84), ('электронный', 85), ('книга', 86), ('формат', 87), ('голос', 88), ('тот', 89), ('аста', 90), ('москва', 91), ('джефри', 92), ('который', 93), ('заставить', 94), ('вспомнить', 95), ('мочь', 96), ('три', 97), ('смотреть', 98), ('глаз', 99)])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo3 = PartOfMorpho3()\n",
    "mo3.vectorizeAsDict(textEnd)\n",
    "print(mo3.dict_len)\n",
    "mo3.dict_len = 100\n",
    "mo3.dictionary.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть, правда, один нюанс. Мы забыли посчитать частоты слов в тексте, когда формировали словарь. Так что придется обойтись просто первой сотней слов текста.  \n",
    "Но сеттеры и геттеры от этого работать не перестали и отражают идею своего использования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
